version: "3.7"
services:
  python:
    image: wynnlin/linebot_makeup:v3
    container_name: python
    ports:
        - "8888:8888"
    volumes:
      - /home/wynn/Templates/:/data
    stdin_open: true
    tty: true

   
  zookeeper:
    image: confluentinc/cp-zookeeper:5.0.0
    hostname: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
  
  hadoop:
    image: wynnlin/hadoop-cluster:v2

  kafka:
    image: confluentinc/cp-kafka:5.0.0
    hostname: kafka
    ports:
      - '9092:9092'
      - '29092:29092'
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://10.120.38.27:9092
      # Following line is needed for Kafka versions 0.11+
      ## in case you run less than 3 Kafka brokers in your
      ## cluster because the broker config
      ##`offsets.topic.replication.factor` (default: 3)
      ##is now enforced upon topic creation
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  spark-master:
    image: spark-master:2.4.4
    container_name: spark-master
    hostname: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    networks: 
      spark-network:
        ipv4_address: 10.5.0.2
    volumes:
       - /mnt/spark-apps:/opt/spark-apps
       - /mnt/spark-data:/opt/spark-data
       - /home/wynn/Templates/:/data
    environment:
      - "SPARK_LOCAL_IP=spark-master"

  spark-worker-1:
    image: spark-worker:2.4.4
    container_name: spark-worker-1
    hostname: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    env_file: ./env-spark-worker.sh
    environment:
      - "SPARK_LOCAL_IP=spark-worker-1"
    networks: 
      spark-network:
        ipv4_address: 10.5.0.3
    volumes:
       - /mnt/spark-apps:/opt/spark-apps
       - /mnt/spark-data:/opt/spark-data
       - /home/wynn/Templates/:/data

  spark-worker-2:
    image: spark-worker:2.4.4
    container_name: spark-worker-2
    hostname: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    env_file: ./env-spark-worker.sh
    environment:
      - "SPARK_LOCAL_IP=spark-worker-2"
    networks: 
      spark-network:
        ipv4_address: 10.5.0.4
    volumes:
       - /mnt/spark-apps:/opt/spark-apps
       - /mnt/spark-data:/opt/spark-data
       - /home/wynn/Templates/:/data
  
  spark-worker-3:
    image: spark-worker:2.4.4
    container_name: spark-worker-3
    hostname: spark-worker-3
    depends_on:
      - spark-master
    ports:
      - "8083:8081"
    env_file: ./env-spark-worker.sh
    environment:
      - "SPARK_LOCAL_IP=spark-worker-3"
    networks: 
      spark-network:
        ipv4_address: 10.5.0.5
    volumes:
       - /mnt/spark-apps:/opt/spark-apps
       - /mnt/spark-data:/opt/spark-data
       - /home/wynn/Templates/:/data
  
  mongo:
    image: mongo:latest
    restart: always
    container_name: 'mongo'
    hostname: mongodb
    ports:
      - '27017:27017'
    networks:
      spark-network:
        ipv4_address: 10.5.0.6
    volumes:
      - /home/wynn/data:/data/db

    

volumes:
  hadoop_namenode:
  hadoop_datanode:
  hadoop_historyserver:

networks:
  spark-network:
    driver: bridge
    ipam:
     driver: default
     config:
       - subnet: 10.5.0.0/16





